{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input and Output\n",
    "\n",
    "> This notebook is the reference code for getting input and output, pandas can read a variety of file types using its pd.read_ methods. Let's take a look at the most common data types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Panda as a library has ability to read/write data from multiple resources.\\\n",
    "* In this notebook we'll be covering just 4 main data sources\n",
    "    * CSV\n",
    "    * Excel\n",
    "    * HTML\n",
    "    * SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To work with html files and SQL databases in PANDAS we will be needing 4 libraries which you can install by running the commands specified below :\n",
    "\n",
    "    1. SQL Alchemy\n",
    "        * conda install sqlalchemy\n",
    "    2. lxml\n",
    "        * conda install lxml\n",
    "    3. HTML5 Library\n",
    "        * conda install html5lib\n",
    "    4. BeautifulSoup4\n",
    "        * conda install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For having gridlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make sure files we are importing are in the same directory in which your current notebook is.\n",
    "* To know the address of current address/directory you are in on your machine just type pwd in any notebook cell\n",
    "* prints working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## CSV\n",
    "\n",
    "### CSV Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('example') # Tab to auto-complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  In order to write to a CSV file we are going to need a dataframe. We create one as specified below :\n",
    "df = pd.read_csv('example') # To read a file use read_fileFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Off of a dataframe we can use pd.to_ to export to any extension the current data frame using the following syntax\n",
    "* DataFrame_Name.to_fileFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('My_output') # Note here we haven't put index = False and Index will also be stored as a column in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output = pd.read_csv('My_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we export df with same name My_output but this time with index = False parameter.\n",
    "df.to_csv('My_output',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output = pd.read_csv('My_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output # Keep in mind while exporting your dataframes, whether or not it is appropriate for you to pass index = False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "\n",
    "## Excel\n",
    "Pandas can read and write excel files, keep in mind, this only imports data. Not formulas or images, having images or macros may cause this read_excel method to crash. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_excel('Excel_Sample.xlsx',sheet_name='Sheet1') \n",
    "# Similar to importing we did above, here only difference is one extra parameter called sheet_name to specify\n",
    "# which sheet you want to import from excel file. sheetname also works but is deprecated now and you might see warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a DataFrame to an excel output is also similar. Just take the DataFrame you want to write to excel and do as below :\n",
    "df.to_excel('Excel_Sample2.xlsx',sheet_name='NewSheet') # dataframe_name.to_excel('file_name.xlsx',sheet_name='optional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel('Excel_Sample2.xlsx',sheet_name='NewSheet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "## HTML\n",
    "\n",
    "You may need to install htmllib5,lxml, and BeautifulSoup4. In your terminal/command prompt run:\n",
    "\n",
    "    conda install lxml\n",
    "    conda install html5lib\n",
    "    conda install BeautifulSoup4\n",
    "\n",
    "Then restart Jupyter Notebook.\n",
    "(or use pip install if you aren't using the Anaconda Distribution)\n",
    "\n",
    "Pandas can read table tabs off of html. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Input\n",
    "\n",
    "Pandas read_html function will read tables off of a webpage and return a list of DataFrame objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html('http://www.fdic.gov/bank/individual/failed/banklist.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  If you look at type of df then you might see that it is a list. Basically what pandas does is makes a list of all the\n",
    "#  <li> tags on the webpage\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0] # Here what we are looking for is the very first element but while working in real life you might have to cycle through\n",
    "# the list returned by the html page until you find it and then put it in as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].head() # Returns the first 5 entries from a dataframe to get a general idea of the fields of a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____\n",
    "# SQL (Optional)\n",
    "\n",
    "* Note: If you are completely unfamiliar with SQL you can check out my other course: \"Complete SQL Bootcamp\" to learn SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas.io.sql module provides a collection of query wrappers to both facilitate data retrieval and to reduce dependency on DB-specific API. Database abstraction is provided by SQLAlchemy if installed. In addition you will need a driver library for your database. Examples of such drivers are psycopg2 for PostgreSQL or pymysql for MySQL. For SQLite this is included in Pythonâ€™s standard library by default. You can find an overview of supported drivers for each SQL dialect in the SQLAlchemy docs.\n",
    "\n",
    "\n",
    "If SQLAlchemy is not installed, a fallback is only provided for sqlite (and for mysql for backwards compatibility, but this is deprecated and will be removed in a future version). This mode requires a Python database adapter which respect the Python DB-API.\n",
    "\n",
    "See also some cookbook examples for some advanced strategies.\n",
    "\n",
    "The key functions are:\n",
    "\n",
    "* read_sql_table(table_name, con[, schema, ...])\t\n",
    "    * Read SQL database table into a DataFrame.\n",
    "* read_sql_query(sql, con[, index_col, ...])\t\n",
    "    * Read SQL query into a DataFrame.\n",
    "* read_sql(sql, con[, index_col, ...])\t\n",
    "    * Read SQL query or database table into a DataFrame.\n",
    "* DataFrame.to_sql(name, con[, flavor, ...])\t\n",
    "    * Write records stored in a DataFrame to a SQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine # Allows us to create very simple SQL engine in the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///:memory:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].to_sql('my_sql_test_table',engine) # df_to_pass.to_sql('name_of_new_sql_table',engine_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = pd.read_sql('my_sql_test_table',con=engine) # Reading back sql table we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voila! Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
